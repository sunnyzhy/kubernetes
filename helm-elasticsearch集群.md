# helm - elasticsearch 集群

## 前言

- 准备三台物理机
    |物理机IP|物理机HostName|角色|
    |--|--|--|
    |192.168.5.163|centos-docker-163|manager|
    |192.168.5.164|centos-docker-164|worker|
    |192.168.5.165|centos-docker-165|worker|

- nfs 根目录: ```/nfs/data```

- 集群相关资料:

    1. Elasticsearch
        ```
        https://github.com/elastic/helm-charts/tree/main/elasticsearch
        
        https://docs.bitnami.com/kubernetes/apps/elasticsearch/get-started/
        ```
 
    2. Kibana
        ```
        https://github.com/elastic/helm-charts/tree/main/kibana
        
        https://docs.bitnami.com/kubernetes/apps/kibana/get-started/
        ```

    3. Kibana 连接 Elasticsearch(带安全验证)
        ```
        https://github.com/bitnami/charts/issues/10076
        ```

- elasticsearch 账号的密码长度必须 ```>= 6```

## 创建 elasticsearch 目录

```bash
# mkdir -p /usr/local/k8s/elasticsearch
```

## 查找 chart

```bash
# helm search repo elasticsearch
NAME                         	CHART VERSION	APP VERSION	DESCRIPTION                                       
aliyun/elasticsearch-exporter	0.1.2        	1.0.2      	Elasticsearch stats exporter for Prometheus       
bitnami/elasticsearch        	19.1.9      	8.3.3      	Elasticsearch is a distributed search and analy...
aliyun/elastalert            	0.1.1        	0.1.21     	ElastAlert is a simple framework for alerting o...
aliyun/kibana                	0.2.2        	6.0.0      	Kibana is an open source data visualization plu...
bitnami/dataplatform-bp2     	12.0.5       	1.0.1      	DEPRECATED This Helm chart can be used for the ...
bitnami/grafana              	7.6.5        	8.3.4      	Grafana is an open source, feature rich metrics...
bitnami/kibana               	10.1.17      	8.3.3      	Kibana is an open source, browser based analyti...
```

## 拉取 chart

```bash
# helm pull bitnami/elasticsearch -d /usr/local/k8s/elasticsearch
```

## 修改 chart 配置

```bash
# tar zxvf /usr/local/k8s/elasticsearch/elasticsearch-19.1.9.tgz -C /usr/local/k8s/elasticsearch

# vim /usr/local/k8s/elasticsearch/elasticsearch/values.yaml
```

```yml
global:
  storageClass: "nfs-client"
  kibanaEnabled: true

extraEnvVars:
  - name: TZ
    value: Asia/Shanghai

security:
  enabled: true
  elasticPassword: "elastic"
  tls:
    autoGenerated: true

master:
  replicaCount: 3
  tolerations:
    - key: "node-role.kubernetes.io/control-plane"
      operator: "Exists"
    - key: "node-role.kubernetes.io/master"
      operator: "Exists"

data:
  replicaCount: 3
  tolerations:
    - key: "node-role.kubernetes.io/control-plane"
      operator: "Exists"
    - key: "node-role.kubernetes.io/master"
      operator: "Exists"

coordinating:
  replicaCount: 2
```

如果 elasticsearch 开启了 ```X-Pack(security.enabled=true)```，就需要配置 kibana ```./charts/kibana/values.yaml```:

```bash
# vim /usr/local/k8s/elasticsearch/elasticsearch/charts/kibana/values.yaml
```

```yml
extraEnvVars:
  - name: TZ
    value: Asia/Shanghai

# tls:
#   enabled: true
#   autoGenerated: true

elasticsearch:
  security:
    auth:
      enabled: true
      kibanaPassword: "elastic"
      createSystemUser: true
      elasticsearchPasswordSecret: "elasticsearch-cluster"
    tls:
      enabled: true
      existingSecret: "elasticsearch-cluster-coordinating-crt"
      usePemCerts: true
```

注:

1. elasticsearch chart 自带 kibana chart，只需配置 ```global.kibanaEnabled=true``` 即可开启 kibana 服务
2. 如果 elasticsearch 开启了 ```X-Pack``` ，则:
   - 务必修改 ```./charts/kibana/values.yaml``` 里 ```elasticsearch.security``` 的相关配置（以下只列出了需要注意的几点配置）:
      - ```elasticsearch.security.tls.existingSecret: <release-name>-coordinating-crt```
      - ```elasticsearch.security.auth.elasticsearchPasswordSecret: <release-name>```，值必须是包含 ```key=elasticsearch-password'``` 的 secret, 默认是 ```<release-name>```
      - ```tls.enabled=true```, 使用 ```https``` 访问 kibana; ```tls.enabled=false```, 使用 ```http``` 访问 kibana

## 重新制作 chart

```bash
# rm -rf /usr/local/k8s/elasticsearch/elasticsearch-19.1.9.tgz

# helm package /usr/local/k8s/elasticsearch/elasticsearch -d /usr/local/k8s/elasticsearch

# tree /usr/local/k8s/elasticsearch
/usr/local/k8s/elasticsearch
├── elasticsearch
│   ├── Chart.lock
│   ├── charts
│   │   ├── common
│   │   │   ├── Chart.yaml
│   │   │   ├── README.md
│   │   │   ├── templates
│   │   │   │   ├── _affinities.tpl
│   │   │   │   ├── _capabilities.tpl
│   │   │   │   ├── _errors.tpl
│   │   │   │   ├── _images.tpl
│   │   │   │   ├── _ingress.tpl
│   │   │   │   ├── _labels.tpl
│   │   │   │   ├── _names.tpl
│   │   │   │   ├── _secrets.tpl
│   │   │   │   ├── _storage.tpl
│   │   │   │   ├── _tplvalues.tpl
│   │   │   │   ├── _utils.tpl
│   │   │   │   ├── validations
│   │   │   │   │   ├── _cassandra.tpl
│   │   │   │   │   ├── _mariadb.tpl
│   │   │   │   │   ├── _mongodb.tpl
│   │   │   │   │   ├── _mysql.tpl
│   │   │   │   │   ├── _postgresql.tpl
│   │   │   │   │   ├── _redis.tpl
│   │   │   │   │   └── _validations.tpl
│   │   │   │   └── _warnings.tpl
│   │   │   └── values.yaml
│   │   └── kibana
│   │       ├── Chart.lock
│   │       ├── charts
│   │       │   └── common
│   │       │       ├── Chart.yaml
│   │       │       ├── README.md
│   │       │       ├── templates
│   │       │       │   ├── _affinities.tpl
│   │       │       │   ├── _capabilities.tpl
│   │       │       │   ├── _errors.tpl
│   │       │       │   ├── _images.tpl
│   │       │       │   ├── _ingress.tpl
│   │       │       │   ├── _labels.tpl
│   │       │       │   ├── _names.tpl
│   │       │       │   ├── _secrets.tpl
│   │       │       │   ├── _storage.tpl
│   │       │       │   ├── _tplvalues.tpl
│   │       │       │   ├── _utils.tpl
│   │       │       │   ├── validations
│   │       │       │   │   ├── _cassandra.tpl
│   │       │       │   │   ├── _mariadb.tpl
│   │       │       │   │   ├── _mongodb.tpl
│   │       │       │   │   ├── _mysql.tpl
│   │       │       │   │   ├── _postgresql.tpl
│   │       │       │   │   ├── _redis.tpl
│   │       │       │   │   └── _validations.tpl
│   │       │       │   └── _warnings.tpl
│   │       │       └── values.yaml
│   │       ├── Chart.yaml
│   │       ├── README.md
│   │       ├── templates
│   │       │   ├── configmap.yaml
│   │       │   ├── deployment.yaml
│   │       │   ├── extra-list.yaml
│   │       │   ├── _helpers.tpl
│   │       │   ├── ingress.yaml
│   │       │   ├── NOTES.txt
│   │       │   ├── plugins-configmap.yaml
│   │       │   ├── pvc.yaml
│   │       │   ├── saved-objects-configmap.yaml
│   │       │   ├── secret.yaml
│   │       │   ├── serviceaccount.yaml
│   │       │   ├── servicemonitor.yaml
│   │       │   ├── service.yaml
│   │       │   └── tls-secret.yaml
│   │       └── values.yaml
│   ├── Chart.yaml
│   ├── README.md
│   ├── templates
│   │   ├── configmap.yaml
│   │   ├── coordinating
│   │   │   ├── hpa.yaml
│   │   │   ├── serviceaccount.yaml
│   │   │   ├── statefulset.yaml
│   │   │   └── svc-headless.yaml
│   │   ├── data
│   │   │   ├── hpa.yaml
│   │   │   ├── serviceaccount.yaml
│   │   │   ├── statefulset.yaml
│   │   │   └── svc-headless.yaml
│   │   ├── extra-list.yaml
│   │   ├── _helpers.tpl
│   │   ├── ingest
│   │   │   ├── hpa.yaml
│   │   │   ├── ingress.yaml
│   │   │   ├── serviceaccount.yaml
│   │   │   ├── service.yaml
│   │   │   ├── statefulset.yaml
│   │   │   └── svc-headless.yaml
│   │   ├── ingress-tls-secrets.yaml
│   │   ├── ingress.yaml
│   │   ├── initialization-configmap.yaml
│   │   ├── master
│   │   │   ├── hpa.yaml
│   │   │   ├── serviceaccount.yaml
│   │   │   ├── statefulset.yaml
│   │   │   └── svc-headless.yaml
│   │   ├── metrics
│   │   │   ├── deployment.yaml
│   │   │   ├── prometheusrule.yaml
│   │   │   ├── servicemonitor.yaml
│   │   │   └── service.yaml
│   │   ├── NOTES.txt
│   │   ├── secrets.yaml
│   │   ├── service.yaml
│   │   └── tls-secret.yaml
│   └── values.yaml
└── elasticsearch-19.1.9.tgz
```

## 部署

```bash
# helm install elasticsearch-cluster /usr/local/k8s/elasticsearch/elasticsearch-19.1.9.tgz -n iot
NAME: elasticsearch-cluster
LAST DEPLOYED: Fri Aug  5 11:49:51 2022
NAMESPACE: iot
STATUS: deployed
REVISION: 1
TEST SUITE: None
NOTES:
CHART NAME: elasticsearch
CHART VERSION: 19.1.9
APP VERSION: 8.3.3

-------------------------------------------------------------------------------
 WARNING

    Elasticsearch requires some changes in the kernel of the host machine to
    work as expected. If those values are not set in the underlying operating
    system, the ES containers fail to boot with ERROR messages.

    More information about these requirements can be found in the links below:

      https://www.elastic.co/guide/en/elasticsearch/reference/current/file-descriptors.html
      https://www.elastic.co/guide/en/elasticsearch/reference/current/vm-max-map-count.html

    This chart uses a privileged initContainer to change those settings in the Kernel
    by running: sysctl -w vm.max_map_count=262144 && sysctl -w fs.file-max=65536

** Please be patient while the chart is being deployed **

  Elasticsearch can be accessed within the cluster on port 9200 at elasticsearch-cluster.iot.svc.cluster.local

  To access from outside the cluster execute the following commands:

    kubectl port-forward --namespace iot svc/elasticsearch-cluster 9200:9200 &
    curl http://127.0.0.1:9200/
```

查看资源:

```bash
# kubectl get sts -n iot | grep elasticsearch
elasticsearch-cluster-coordinating   2/2     43m
elasticsearch-cluster-data           3/3     43m
elasticsearch-cluster-master         3/3     43m

# kubectl get pod -n iot -o wide | grep elasticsearch
elasticsearch-cluster-coordinating-0               1/1     Running     0               44m     10.244.1.189   centos-docker-164   <none>           <none>
elasticsearch-cluster-coordinating-1               1/1     Running     0               44m     10.244.2.156   centos-docker-165   <none>           <none>
elasticsearch-cluster-data-0                       1/1     Running     0               44m     10.244.2.157   centos-docker-165   <none>           <none>
elasticsearch-cluster-data-1                       1/1     Running     0               44m     10.244.1.191   centos-docker-164   <none>           <none>
elasticsearch-cluster-data-2                       1/1     Running     0               44m     10.244.0.169   centos-docker-163   <none>           <none>
elasticsearch-cluster-kibana-67b5f65bf7-pdg65      1/1     Running     0               44m     10.244.1.188   centos-docker-164   <none>           <none>
elasticsearch-cluster-master-0                     1/1     Running     0               44m     10.244.2.158   centos-docker-165   <none>           <none>
elasticsearch-cluster-master-1                     1/1     Running     0               44m     10.244.1.190   centos-docker-164   <none>           <none>
elasticsearch-cluster-master-2                     1/1     Running     0               44m     10.244.0.168   centos-docker-163   <none>           <none>

# kubectl get pvc,pv -n iot | grep elasticsearch
persistentvolumeclaim/data-elasticsearch-cluster-data-0        Bound    pvc-67f8bc79-674a-4220-8cef-a447414521ec   8Gi        RWO            nfs-client     44m
persistentvolumeclaim/data-elasticsearch-cluster-data-1        Bound    pvc-21ce479f-6592-4895-adc7-37ed64aa1015   8Gi        RWO            nfs-client     44m
persistentvolumeclaim/data-elasticsearch-cluster-data-2        Bound    pvc-cc9fd146-a0b3-4478-bf01-d36a7fc0f4ed   8Gi        RWO            nfs-client     44m
persistentvolumeclaim/data-elasticsearch-cluster-master-0      Bound    pvc-e0bb1291-3635-4b09-b848-5310c5b590a2   8Gi        RWO            nfs-client     44m
persistentvolumeclaim/data-elasticsearch-cluster-master-1      Bound    pvc-e0307d6e-dd1b-4c53-94e4-377e44efaae2   8Gi        RWO            nfs-client     44m
persistentvolumeclaim/data-elasticsearch-cluster-master-2      Bound    pvc-9dff3c11-73c7-4fda-886f-3ab4b4cf282b   8Gi        RWO            nfs-client     44m
persistentvolumeclaim/elasticsearch-cluster-kibana             Bound    pvc-647659bb-91e8-494d-9d8e-af8d8b49dfa8   10Gi       RWO            nfs-client     44m
persistentvolume/pvc-21ce479f-6592-4895-adc7-37ed64aa1015   8Gi        RWO            Delete           Bound    iot/data-elasticsearch-cluster-data-1        nfs-client              44m
persistentvolume/pvc-647659bb-91e8-494d-9d8e-af8d8b49dfa8   10Gi       RWO            Delete           Bound    iot/elasticsearch-cluster-kibana             nfs-client              44m
persistentvolume/pvc-67f8bc79-674a-4220-8cef-a447414521ec   8Gi        RWO            Delete           Bound    iot/data-elasticsearch-cluster-data-0        nfs-client              44m
persistentvolume/pvc-9dff3c11-73c7-4fda-886f-3ab4b4cf282b   8Gi        RWO            Delete           Bound    iot/data-elasticsearch-cluster-master-2      nfs-client              44m
persistentvolume/pvc-cc9fd146-a0b3-4478-bf01-d36a7fc0f4ed   8Gi        RWO            Delete           Bound    iot/data-elasticsearch-cluster-data-2        nfs-client              44m
persistentvolume/pvc-e0307d6e-dd1b-4c53-94e4-377e44efaae2   8Gi        RWO            Delete           Bound    iot/data-elasticsearch-cluster-master-1      nfs-client              44m
persistentvolume/pvc-e0bb1291-3635-4b09-b848-5310c5b590a2   8Gi        RWO            Delete           Bound    iot/data-elasticsearch-cluster-master-0      nfs-client              44m

# kubectl get svc -n iot | grep elasticsearch
elasticsearch-cluster                   ClusterIP   10.98.156.14     <none>        9200/TCP,9300/TCP                                                                            46m
elasticsearch-cluster-coordinating-hl   ClusterIP   None             <none>        9200/TCP,9300/TCP                                                                            46m
elasticsearch-cluster-data-hl           ClusterIP   None             <none>        9200/TCP,9300/TCP                                                                            46m
elasticsearch-cluster-kibana            ClusterIP   10.97.58.185     <none>        5601/TCP                                                                                     46m
elasticsearch-cluster-master-hl         ClusterIP   None             <none>        9200/TCP,9300/TCP                                                                            46m
```

## 内部访问 elasticsearch 集群

在 elasticsearch-cluster-coordinating-0 的 pod 里新建 ```foo``` 索引:

```bash
# kubectl exec -it elasticsearch-cluster-coordinating-0 -n iot -- /bin/sh

$ curl -k -u elastic:elastic https://localhost:9200/_cat/indices?v
health status index uuid pri rep docs.count docs.deleted store.size pri.store.size

$ curl -k -u elastic:elastic -XPUT https://localhost:9200/foo/?pretty
{
  "acknowledged" : true,
  "shards_acknowledged" : true,
  "index" : "foo"
}

$ curl -k -u elastic:elastic https://localhost:9200/_cat/indices?v
health status index uuid                   pri rep docs.count docs.deleted store.size pri.store.size
green  open   foo   guioAO1vSt2u7onjZ3t6FA   1   1          0            0       450b           225b
```

在 elasticsearch-cluster-coordinating-1 的 pod 里查看索引同步情况:

```bash
# kubectl exec -it elasticsearch-cluster-coordinating-1 -n iot -- /bin/sh

$ curl -k -u elastic:elastic https://localhost:9200/_cat/indices?v
health status index uuid                   pri rep docs.count docs.deleted store.size pri.store.size
green  open   foo   guioAO1vSt2u7onjZ3t6FA   1   1          0            0       450b           225b
```

在任意 pod 里查看集群的健康状态:

```bash
$ curl -k -u elastic:elastic https://localhost:9200/_cluster/health?pretty=true
{
  "cluster_name" : "elastic",
  "status" : "green",
  "timed_out" : false,
  "number_of_nodes" : 8,
  "number_of_data_nodes" : 3,
  "active_primary_shards" : 11,
  "active_shards" : 22,
  "relocating_shards" : 0,
  "initializing_shards" : 0,
  "unassigned_shards" : 0,
  "delayed_unassigned_shards" : 0,
  "number_of_pending_tasks" : 0,
  "number_of_in_flight_fetch" : 0,
  "task_max_waiting_in_queue_millis" : 0,
  "active_shards_percent_as_number" : 100.0
}
```

## 外部访问 elasticsearch 集群

创建 NodePort 类型的 Service:

```bash
# vim /usr/local/k8s/elasticsearch/service.yaml
```

```yml
apiVersion: v1
kind: Service
metadata:
  name: elasticsearch-cluster-service
  namespace: iot
spec:
  selector:
    app.kubernetes.io/component: coordinating-only
    app.kubernetes.io/instance: elasticsearch-cluster
    app.kubernetes.io/name: elasticsearch
  ports:
    - name: tcp-rest-api
      protocol: TCP
      port: 9200
      targetPort: rest-api
      nodePort: 30200
    - name: tcp-transport
      protocol: TCP
      port: 9300
      targetPort: transport
      nodePort: 30300
  type: NodePort
```

```bash
# kubectl apply -f /usr/local/k8s/elasticsearch/service.yaml

# kubectl get svc elasticsearch-cluster-service -n iot
NAME                            TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)                         AGE
elasticsearch-cluster-service   NodePort   10.111.32.236   <none>        9200:30200/TCP,9300:30300/TCP   18s
```

外部服务器连接 elasticsearch 集群:

```bash
# curl -k -u elastic:elastic -XPUT https://192.168.5.163:30200/bar/?pretty
{
  "acknowledged" : true,
  "shards_acknowledged" : true,
  "index" : "bar"
}

# curl -k -u elastic:elastic -XGET https://192.168.5.163:30200/_cat/indices?v
health status index uuid                   pri rep docs.count docs.deleted store.size pri.store.size
green  open   bar   juntQJk-ToWD8WiY-7xsUQ   1   1          0            0       450b           225b
green  open   foo   guioAO1vSt2u7onjZ3t6FA   1   1          0            0       450b           225b

# curl -k -u elastic:elastic -XDELETE https://192.168.5.163:30200/foo?pretty
{
  "acknowledged" : true
}

# curl -k -u elastic:elastic -XGET https://192.168.5.163:30200/_cat/indices?v
health status index uuid                   pri rep docs.count docs.deleted store.size pri.store.size
green  open   bar   juntQJk-ToWD8WiY-7xsUQ   1   1          0            0       450b           225b

# curl -k -u elastic:elastic -XGET https://192.168.5.163:30200/_cluster/health?pretty=true
{
  "cluster_name" : "elastic",
  "status" : "green",
  "timed_out" : false,
  "number_of_nodes" : 8,
  "number_of_data_nodes" : 3,
  "active_primary_shards" : 12,
  "active_shards" : 24,
  "relocating_shards" : 0,
  "initializing_shards" : 0,
  "unassigned_shards" : 0,
  "delayed_unassigned_shards" : 0,
  "number_of_pending_tasks" : 0,
  "number_of_in_flight_fetch" : 0,
  "task_max_waiting_in_queue_millis" : 0,
  "active_shards_percent_as_number" : 100.0
}
```

查看系统用户:

```bash
# curl -k -u elastic:elastic -XGET https://192.168.5.163:30200/_security/user?pretty
{
  "elastic" : {
    "username" : "elastic",
    "roles" : [
      "superuser"
    ],
    "full_name" : null,
    "email" : null,
    "metadata" : {
      "_reserved" : true
    },
    "enabled" : true
  },
  "kibana" : {
    "username" : "kibana",
    "roles" : [
      "kibana_system"
    ],
    "full_name" : null,
    "email" : null,
    "metadata" : {
      "_reserved" : true,
      "_deprecated" : true,
      "_deprecated_reason" : "Please use the [kibana_system] user instead."
    },
    "enabled" : true
  },
  "kibana_system" : {
    "username" : "kibana_system",
    "roles" : [
      "kibana_system"
    ],
    "full_name" : null,
    "email" : null,
    "metadata" : {
      "_reserved" : true
    },
    "enabled" : true
  },
  "logstash_system" : {
    "username" : "logstash_system",
    "roles" : [
      "logstash_system"
    ],
    "full_name" : null,
    "email" : null,
    "metadata" : {
      "_reserved" : true
    },
    "enabled" : true
  },
  "beats_system" : {
    "username" : "beats_system",
    "roles" : [
      "beats_system"
    ],
    "full_name" : null,
    "email" : null,
    "metadata" : {
      "_reserved" : true
    },
    "enabled" : true
  },
  "apm_system" : {
    "username" : "apm_system",
    "roles" : [
      "apm_system"
    ],
    "full_name" : null,
    "email" : null,
    "metadata" : {
      "_reserved" : true
    },
    "enabled" : true
  },
  "remote_monitoring_user" : {
    "username" : "remote_monitoring_user",
    "roles" : [
      "remote_monitoring_collector",
      "remote_monitoring_agent"
    ],
    "full_name" : null,
    "email" : null,
    "metadata" : {
      "_reserved" : true
    },
    "enabled" : true
  }
}
```

## 外部访问 kibana

创建 NodePort 类型的 Service:

```bash
# vim /usr/local/k8s/elasticsearch/kibana-service.yaml
```

```yml
apiVersion: v1
kind: Service
metadata:
  name: elasticsearch-cluster-kibana-service
  namespace: iot
spec:
  selector:
    app.kubernetes.io/instance: elasticsearch-cluster
    app.kubernetes.io/name: kibana
  ports:
    - name: http
      protocol: TCP
      port: 5601
      targetPort: http
      nodePort: 30601
  type: NodePort
```

```bash
# kubectl apply -f /usr/local/k8s/elasticsearch/kibana-service.yaml

# kubectl get svc elasticsearch-cluster-kibana-service -n iot
NAME                                   TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)          AGE
elasticsearch-cluster-kibana-service   NodePort   10.102.93.36   <none>        5601:30601/TCP   15s
```

在外部服务器的浏览器地址栏里输入以下链接， ```用户名/密码: elastic/elastic```:

- ```kibana.tls.enabled=false```, 使用 ```http``` 访问 kibana:

    ```
    http://192.168.5.163:30601
    ```

- ```kibana.tls.enabled=true```, 使用 ```https``` 访问 kibana:

    ```
    https://192.168.5.163:30601
    ```

## Elasticsearch 角色

1. master

    ```
    master 节点具备主节点的选举权，有资格成为主节点，主节点控制整个集群的元数据 (metadata)，比如索引的新增、删除、分片分配等。

    角色配置方式：node.master: true
    ```

2. data

    ```
    该节点和应用创建连接、接收索引请求，会存储分配在该 node 上的 shard 的数据并负责这些 shard 的写入、查询等，ES 集群的性能取决于该节点的个数（每个节点最优配置的情况下）；
    data 节点的分片执行查询语句、获得查询结果后将结果反馈给 Coordinating，此过程较消耗硬件资源。

    角色配置方式：node.data: true
    ```

3. coordinating

    ```
    该节点和检索应用创建连接、接受检索请求，但其本身不负责存储数据，可当负责均衡节点，Coordinating 节点不占用 io、cpu 和内存；
    Coordinating 节点接受搜索请求后将请求转发到与查询条件相关的多个 data 节点的分片上，然后多个 data 节点的分片执行查询语句或者查询结果再返回给 Coordinating 节点，Coordinating 来把各个 data 节点的返回结果进行整合、排序等一系列操作后再将最终结果返回给用户请求。

    角色配置方式：node.master: false，node.data: false
    ```

4. ingest

    ```
    可以在任何节点上启用 ingest，甚至使用专门的 ingest nodes；
    Ingest node 专门对索引的文档做预处理，发生在对真实文档建立索引之前。在建立索引对文档预处理之前，先定义一个管道（pipeline），管道里指定了一系列的处理器。每个处理器能够把文档按照某种特定的方式转换。比如在管道里定义一个从某个文档中移除字段的处理器，紧接着一个重命名字段的处理器。集群的状态也会被存储到配置的管道内。定义一个管道，简单的在索引或者bulk request(一种批量请求方法)操作上定义 pipeline 参数,这样 ingest node 就会知道哪个管道在使用。

    角色配置方式：node.ingest: true
    ```

## FAQ

### curl: (52) Empty reply from server

原因: elasticsearch 开启了 X-Pack，所以不允许使用 ```http``` 访问

解决方法: 使用 ```https``` 访问
